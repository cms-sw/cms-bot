#!/bin/sh -ex
function process_nano(){
  mkdir -p $1
  pushd $1
    for r in $(ls -d $2/*/step2.root 2>/dev/null); do
      WF_DIR=$(dirname $r)
      [ -e ${WF_DIR}/JobReport2.xml ] || continue
      while [ $(jobs -p | wc -l) -ge ${NUM_PROC} ] ; do sleep 0.1 ; done
      WF=$(basename ${WF_DIR} | cut -d_ -f1)
      ${NANO_TEST_DIR}/inspectNanoFile.py $r -j ${WF}-size.json &
      while [ $(jobs -p | wc -l) -ge ${NUM_PROC} ] ; do sleep 0.1 ; done
      ${NANO_TEST_DIR}/get_timing_from_jobreport.py ${WF_DIR}/JobReport2.xml ${WF}-timing.json &
    done
  popd
}

function nano_summary(){
  pushd $WORKSPACE/results/nano
    WFS=""
    rm -f NANO_report.md
    for wf in $(ls -d *-size.json | sed 's|-size.json||') ; do
      ok_wf=true
      for f in ${wf}-timing.json ref/${wf}-size.json ref/${wf}-size.json ; do
        if [ ! -e $f ] ; then echo " - Nano ERROR: Missing $f" >> NANO_report.md ; ok_wf=false ; fi
      done
      $ok_wf && WFS="${WFS} ${wf}"
    done
    if [ "${WFS}" != "" ] ; then
      ${NANO_TEST_DIR}/compare_sizes_json.py -H -f md --base "{}-size.json,{}-timing.json" --ref "./ref" ${WFS} >> NANO_report.md
    else
     echo " - No valid nano workflows found" >> NANO_report.md
    fi
  popd
}

source $(dirname $0)/setup-pr-test-env.sh
TEST_FLAVOR_STR=""
UC_TEST_FLAVOR=$(echo ${TEST_FLAVOR} | tr '[a-z]' '[A-Z]')
GH_COMP_CONTEXT="comparison"
if [ "${TEST_FLAVOR}" != "" ] ; then
  GH_COMP_CONTEXT="${GH_COMP_CONTEXT}/${TEST_FLAVOR}"
  TEST_FLAVOR_STR="_${UC_TEST_FLAVOR}"
fi

NUM_PROC=$(nproc)
export SCRAM_ARCH=$ARCHITECTURE
if [ "X$COMPARISON_ARCH" = "X" ] ; then COMPARISON_ARCH=$ARCHITECTURE; fi
cd $WORKSPACE
rm -rf $WORKSPACE/results $WORKSPACE/upload
JR_COMP_DIR=$WORKSPACE/results/JR-comparison
mkdir -p $WORKSPACE/upload ${JR_COMP_DIR} $WORKSPACE/data
rm -f $WORKSPACE/ALL_DONE
if [ "X$COMPARISON_RELEASE" = "X" ] ; then COMPARISON_RELEASE=$CMSSW_VERSION; fi
if [ "$REAL_ARCH" = "" ] ; then REAL_ARCH="-GenuineIntel"; fi
PR_NUM=$(echo ${PULL_REQUEST} | md5sum | sed 's| .*||' | cut -c27-33)
BASELINE_DIR=ib-baseline-tests/$COMPARISON_RELEASE/$COMPARISON_ARCH/$REAL_ARCH/matrix${TEST_FLAVOR}-results
PR_BASELINE_JOBDIR=pull-request-integration/${UPLOAD_UNIQ_ID}
PR_BASELINE_DIR=${PR_BASELINE_JOBDIR}/runTheMatrix${UC_TEST_FLAVOR}-results
JENKINS_ARTIFACTS_URL="https://cmssdt.cern.ch/SDT/jenkins-artifacts"
PR_RESULT_URL="${JENKINS_ARTIFACTS_URL}/${PR_BASELINE_JOBDIR}"
RESULTS_FILE=$WORKSPACE/comparison${UC_TEST_FLAVOR}.txt
COMP_UPLOAD_DIR="baseLineComparisons${UC_TEST_FLAVOR}/${COMPARISON_RELEASE}+${PR_NUM}/${BUILD_NUMBER}"
DAS_NON_CONSISTENT_WFS_FILE=wf_non_consistent_das.txt
MAPPING_FILE=wf_mapping.txt
ERRORS_FILE=wf_errors.txt

#Make sure Release baseline has been deployed
echo -n "Waiting for baseline .."
while [ ! -d ${CVMFS_ARTIFACT_DIR}/${BASELINE_DIR} ] ; do echo -n '.'; sleep 10 ; done
echo ''
if [ "${MATRIX_ARGS}" != "" ] ; then
 echo "${MATRIX_ARGS}"  | tr ';' '\n' | while IFS= read -r args; do
   args=$(echo "$args" | sed -e 's|.*\(-l *[^ ]*\).*|\1|;s|-|\\-|')
   echo -n "Waiting for \"$args\" .."
   while [ $(grep "$args" ${CVMFS_ARTIFACT_DIR}/${BASELINE_DIR}/workflows-*.done 2>/dev/null| wc -l) -eq 0 ] ; do
     echo -n '.'
     sleep 10
   done
   echo "Done: \"$args\""
 done
fi

mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Running" || true

if $DQM_COMPARISON_TEST ; then
  if ! which compareDQMOutput.py >/dev/null 2>&1 ; then
    DQM_COMPARISON_TEST=false
  fi
fi

NANO_TEST=false
if [ "${UC_TEST_FLAVOR}" = "NANO" ] ; then
  NANO_TEST_DIR=${CMSSW_BASE}/src/PhysicsTools/NanoAOD/test
  [ -e ${NANO_TEST_DIR} ] || NANO_TEST_DIR=${CMSSW_RELEASE_BASE}/src/PhysicsTools/NanoAOD/test
  [ -x ${NANO_TEST_DIR}/compare_sizes_json.py ] && NANO_TEST=true
fi

cd $WORKSPACE/results
echo "Downloading Ref: `date`"
get_jenkins_artifacts ${BASELINE_DIR}/    $WORKSPACE/data/$COMPARISON_RELEASE/ || true
echo "Downloading PR: `date`"
${NANO_TEST} && process_nano nano/ref $WORKSPACE/data/$COMPARISON_RELEASE
get_jenkins_artifacts ${PR_BASELINE_DIR}/ $WORKSPACE/data/PR-${PR_NUM}/
echo "Done Downloading `date`"
${NANO_TEST} && process_nano nano $WORKSPACE/data/PR-${PR_NUM}

cat $WORKSPACE/data/$COMPARISON_RELEASE/wf_mapping.*txt | sort | uniq > $WORKSPACE/$MAPPING_FILE
cat $WORKSPACE/data/$COMPARISON_RELEASE/wf_errors.*txt  | sort | uniq > $WORKSPACE/$ERRORS_FILE
cat $WORKSPACE/$MAPPING_FILE
cat $WORKSPACE/$ERRORS_FILE
WFS_WITH_ERRORS=''
for wf in ${WORKFLOWS_LIST//,/ }
do
  WF_PATH=`grep "^${wf}_" $WORKSPACE/$MAPPING_FILE` || true
  if [ "X$WF_PATH" = X ]; then
    ERR_DETAILS=`grep "$wf;" $WORKSPACE/$ERRORS_FILE` || true
    if [ "X$ERR_DETAILS" = X ]; then
      WFS_WITH_ERRORS=$ERR_DETAILS,$wf';1'
    else
      WFS_WITH_ERRORS=$ERR_DETAILS,$WFS_WITH_ERRORS
    fi
  else
    echo "Going to compare: $wf"
    echo $WF_PATH
    echo ""
    WORKFLOWS_TO_COMPARE=$WORKFLOWS_TO_COMPARE,$WF_PATH
  fi
done

#remove first ,
WORKFLOWS_TO_COMPARE=`echo $WORKFLOWS_TO_COMPARE | sed 's/^.//'`
echo $WORKFLOWS_TO_COMPARE
for WF in ${WORKFLOWS_TO_COMPARE//,/ }; do

  WF_DIR=`echo $WF | cut -d "/" -f1`
  WF_NUMBER=`echo $WF | cut -d'_' -f1`
  WF_FILE=$(basename $WF)

  mkdir -p $WORKSPACE/results/files/$WF_DIR
  ln -s $WORKSPACE/data/$COMPARISON_RELEASE/${WF} $WORKSPACE/results/files/$WF_DIR/$COMPARISON_RELEASE-$WF_FILE

  if [ -f $WORKSPACE/data/$COMPARISON_RELEASE/$WF_DIR/step1_dasquery.log ] ; then
    grep '/store/' $WORKSPACE/data/$COMPARISON_RELEASE/$WF_DIR/step1_dasquery.log > $WORKSPACE/results/files/$WF_DIR/$COMPARISON_RELEASE-step1_dasquery.log || true
  fi
  if [ -f $WORKSPACE/data/PR-${PR_NUM}/$WF ] ; then
    ln -s $WORKSPACE/data/PR-${PR_NUM}/$WF $WORKSPACE/results/files/$WF_DIR/$PR_NUM-$WF_FILE
  fi
  if [ -f $WORKSPACE/data/PR-${PR_NUM}/$WF_DIR/step1_dasquery.log ] ; then
    grep '/store/' $WORKSPACE/data/PR-${PR_NUM}/$WF_DIR/step1_dasquery.log > $WORKSPACE/results/files/$WF_DIR/$PR_NUM-step1_dasquery.log || true
  fi

  # check that the step1_dasquery.log files are correct.
  NUM_FILES=$(( `ls $WORKSPACE/results/files/$WF_DIR/*-step1_dasquery.log | wc -l` ))
  # if there is only one of them something is wrong, but if there is none is ok
  if [ "$NUM_FILES" -eq "1" ]; then
    WFS_WITH_DAS_INCONSISTENCY=$WF_NUMBER,$WFS_WITH_DAS_INCONSISTENCY
  elif [ "$NUM_FILES" -eq "2" ]; then
    PR_DAS_QUERY_LOG="$WORKSPACE/results/files/$WF_DIR/$PR_NUM-step1_dasquery.log"
    BASELINE_DAS_QUERY_LOG="$WORKSPACE/results/files/$WF_DIR/$COMPARISON_RELEASE-step1_dasquery.log"
    THEY_DIFFER=`diff -q "$PR_DAS_QUERY_LOG" "$BASELINE_DAS_QUERY_LOG" || true`
    if [ "X$THEY_DIFFER" != X ]; then
      diff -u "$PR_DAS_QUERY_LOG" "$BASELINE_DAS_QUERY_LOG" || true
      WFS_WITH_DAS_INCONSISTENCY=$WF_NUMBER,$WFS_WITH_DAS_INCONSISTENCY
    fi
  fi 
done

echo $WFS_WITH_DAS_INCONSISTENCY >> $WORKSPACE/$DAS_NON_CONSISTENT_WFS_FILE

echo "Finished downloading files at `date`:"
echo "COMPARISON${TEST_FLAVOR_STR};RUNNING,Comparison with the ${UC_TEST_FLAVOR} baseline,See results,See results" >> ${RESULTS_FILE}
if [ "$DRY_RUN" = "" ] ; then
  send_jenkins_artifacts ${RESULTS_FILE} ${PR_BASELINE_JOBDIR}/testsResults/comparison${UC_TEST_FLAVOR}.txt
fi

if $DQM_COMPARISON_TEST ; then
  mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Running DQM bin by bin comparison" || true
  (compareDQMOutput.py -b $WORKSPACE/data/$COMPARISON_RELEASE/ -p $WORKSPACE/data/PR-${PR_NUM} -o $CMS_BOT_DIR/dqm-comparison/dqmComparisonOutput/ -l "$PULL_REQUESTS" -t ${BUILD_ID} -r $COMPARISON_RELEASE -s $WORKSPACE/upload/ -j $NUM_PROC > $WORKSPACE/upload/dqmBinByBinLog.log 2>&1) || true
  echo "DQM_BIN_BY_BIN_COMPARISON${TEST_FLAVOR_STR};OK,DQM bin by bin ${UC_TEST_FLAVOR} comparison,See results,/SDT/jenkins-artifacts/${COMP_UPLOAD_DIR}/dqm-histo-comparison-summary.html" >> ${RESULTS_FILE}
fi

# --------------------------------------------------------------------------
# JR-Comparison
# --------------------------------------------------------------------------

#This is used mainly for testing. In jenkins the 3 forms of comparisons are always run. But if you are testing you can control
#which comparison is run.
if [ "X$RUN_JR_COMP" = Xtrue ]; then
  mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Running JR comparion" || true
  cd $JR_COMP_DIR
  cp $CMS_BOT_DIR/comparisons/validateJR.sh  $JR_COMP_DIR
  chmod +x $JR_COMP_DIR/validateJR.sh
  cp $CMS_BOT_DIR/comparisons/validate.C     $JR_COMP_DIR
  cp $CMS_BOT_DIR/comparisons/validateJR.py    $JR_COMP_DIR
  chmod +x $JR_COMP_DIR/validateJR.py
  export VALIDATE_C_SCRIPT=${JR_COMP_DIR}/validate.C

  echo "Start JR comparison at `date`"
  echo  "$JR_COMP_DIR/validateJR.sh $WORKSPACE/data/PR-$PR_NUM $WORKSPACE/data/$COMPARISON_RELEASE >> $JR_COMP_DIR/validateJR.log 2>&1" > $JR_COMP_DIR/command
  ($JR_COMP_DIR/validateJR.sh $WORKSPACE/data/PR-$PR_NUM $WORKSPACE/data/$COMPARISON_RELEASE >> $JR_COMP_DIR/validateJR.log 2>&1) || true

  echo "Finished with JR comparison at `date`:"
fi

#Run product size comparison script for Phase2 workflow
mkdir compareProducts && cd compareProducts
cp $CMS_BOT_DIR/comparisons/compareProducts.* ./
./compareProducts.sh $WORKSPACE/data/PR-$PR_NUM/136.874_*/step3.root $WORKSPACE/data/$COMPARISON_RELEASE/136.874_*/step3.root _ 100 10 > products_AOD.log || true
./compareProducts.sh $WORKSPACE/data/PR-$PR_NUM/136.874_*/step3_inMINIAOD.root $WORKSPACE/data/$COMPARISON_RELEASE/136.874_*/step3_inMINIAOD.root _ 100 10 > products_MINIAOD.log || true
mv products_AOD.log $WORKSPACE/upload/products_AOD.log
mv products_MINIAOD.log $WORKSPACE/upload/products_MINIAOD.log
cd .. 

#set +x
# --------------------------------------------------------------------------
# Default Comparison
# --------------------------------------------------------------------------
if [ "X$RUN_DEFAULT_COMP" = Xtrue ]; then
  mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Running default comparison" || true
  echo "Started with default comparison at `date`"
  
  RELMON_COMP_DIR=$WORKSPACE/results/default-comparison
  mkdir $RELMON_COMP_DIR

  if [ "X$RUN_JR_COMP" = Xtrue ]; then
    RELMON_COMP_PARAMS_FILE=$RELMON_COMP_DIR/RelMonComparisonParams.txt
    if ! $CMS_BOT_DIR/comparisons/analyzeFWComparison.py $JR_COMP_DIR $RELMON_COMP_PARAMS_FILE -R >> $RELMON_COMP_DIR/RelMonAssignedParameters.log 2>&1 ; then
      cat $RELMON_COMP_DIR/RelMonAssignedParameters.log
      exit 1
    fi
  fi

  touch $WORKSPACE/results/default-comparison/done-0
  for WF in ${WORKFLOWS_TO_COMPARE//,/ }; do 

    WF_FILE=$(basename $WF)
    WF_DIR=`echo $WF | cut -d "/" -f1`
    WF_NUMBER=`echo $WF | cut -d'_' -f1`

    #create the output dir
    OUTPUT_DIR=$WORKSPACE/results/default-comparison/$WF_DIR
    mkdir -p $OUTPUT_DIR

    # If there is a file assigning custom thresholds from the results of the FWlite (JR) comparison, use it
    if [ "X$RUN_JR_COMP" = Xtrue ]; then
      eval $( cat $RELMON_COMP_PARAMS_FILE | grep "FOR_WF=$WF_NUMBER;" )
      echo "TH=$TH"
      if [ "${TH}" = "" ] ; then TH="0.999999999999"; echo "Overriding TH=$TH" ; fi
      TH_PARAM="-t $TH "
    fi

    #requires checking out Utilities/RelMon from the release. It has already been done at the begining of this script. 

    # create a mini script for running this comparisons in parallel
    echo '#!/bin/sh -ex' > $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    echo "ERR=0" >> $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    echo "compare_using_files.py -B DQM/TimerService@3 $WORKSPACE/results/files/$WF_DIR/$COMPARISON_RELEASE-$WF_FILE $WORKSPACE/results/files/$WF_DIR/$PR_NUM-$WF_FILE -o $OUTPUT_DIR --metas \" $COMPARISON_RELEASE @@@ $COMPARISON_RELEASE + $PR_NUM \" --use_black_file -C -R -p --no_successes -s b2b $TH_PARAM --standalone >> ${OUTPUT_DIR}RelMonComp-$WF_NUMBER.log 2>&1 || ERR=1" >> $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    echo "cp $OUTPUT_DIR/RelMonSummary.html $OUTPUT_DIR/index.html || true" >> $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    echo "touch $WORKSPACE/results/default-comparison/done-$WF_NUMBER" >> $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    echo 'exit $ERR' >> $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    chmod 755 $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    while [ $(jobs -p | wc -l) -ge ${NUM_PROC} ] ; do sleep 5 ; done
    echo "Running $WORKSPACE/results/default-comparison/command-$WF_NUMBER"
    ($WORKSPACE/results/default-comparison/command-$WF_NUMBER > ${OUTPUT_DIR}/cmd.log 2>&1 || touch $WORKSPACE/results/default-comparison/error-$WF_NUMBER) &
  done
fi

# ----------------------------------------------------------------------------
# Alternative Comparison
# ----------------------------------------------------------------------------

if [ "X$RUN_ALT_COMP" = Xtrue ]; then
  mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Running alternative comparison" || true
  echo "Started with alternative comparison at `date`"
  
  ALT_COMP_DIR=$WORKSPACE/results/alternative-comparison
  mkdir -p $ALT_COMP_DIR
  DQM_COMP_PARAMS_FILE=$ALT_COMP_DIR/comparisonParams.txt

  if [ "X$RUN_JR_COMP" = Xtrue ]; then
    $CMS_BOT_DIR/comparisons/analyzeFWComparison.py $JR_COMP_DIR $DQM_COMP_PARAMS_FILE >> $ALT_COMP_DIR/assignedParameters.log 2>&1
  fi
  for WF in ${WORKFLOWS_TO_COMPARE//,/ }; do 

    WF_FILE=$(basename $WF)
    WF_DIR=`echo $WF | cut -d "/" -f1`
    WF_NUMBER=`echo $WF | cut -d'_' -f1`
    BASE_FILE=$WORKSPACE/results/files/$WF_DIR/$COMPARISON_RELEASE-$WF_FILE
    COMP_FILE=$WORKSPACE/results/files/$WF_DIR/$PR_NUM-$WF_FILE
  
    mkdir -p $ALT_COMP_DIR/$WF_NUMBER
    cp $CMS_BOT_DIR/comparisons/compareValHists.C $ALT_COMP_DIR/$WF_NUMBER
    cp $CMS_BOT_DIR/comparisons/makeDiff.sh $ALT_COMP_DIR/$WF_NUMBER

    eval $( cat $DQM_COMP_PARAMS_FILE | grep "FOR_WF=$WF_NUMBER;" )
    if [ "${MOD}" = "" ] ; then MOD=0; echo "Overriding MOD=$MOD";  fi
    echo "MOD=$MOD"

    # create a mini script for running this comparisons in parallel
    echo '#!/bin/sh -ex' > $ALT_COMP_DIR/command-$WF_NUMBER
    echo "ERR=0" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "cd $ALT_COMP_DIR/$WF_NUMBER" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "$ALT_COMP_DIR/$WF_NUMBER/makeDiff.sh $BASE_FILE $COMP_FILE $WF_NUMBER-result.ps 0 $MOD || ERR=1" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "mv diff.ps $ALT_COMP_DIR/$WF_NUMBER-result.ps || true" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "mv diff.pdf $ALT_COMP_DIR/$WF_NUMBER-result.pdf || true" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "gzip -f $ALT_COMP_DIR/$WF_NUMBER-result.ps || true" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "gzip -f $ALT_COMP_DIR/$WF_NUMBER-result.pdf || true" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo 'exit $ERR' >> $ALT_COMP_DIR/command-$WF_NUMBER

    chmod 755 $ALT_COMP_DIR/command-$WF_NUMBER
    while [ $(jobs -p | wc -l) -ge ${NUM_PROC} ] ; do sleep 5 ; done
    echo "Running $ALT_COMP_DIR/command-$WF_NUMBER"
    ($ALT_COMP_DIR/command-$WF_NUMBER > $ALT_COMP_DIR/runDQMComp-$WF_NUMBER.log 2>&1 || touch $ALT_COMP_DIR/error-$WF_NUMBER) &
  done
fi

if [ -e $WORKSPACE/results/default-comparison/done-0 ] ; then
  while [ $(ls -d $WORKSPACE/results/default-comparison/done-* | wc -l) -le $(ls -d $WORKSPACE/results/default-comparison/command-* | wc -l) ] ; do
    sleep 60
    echo "Jobs Running: $(jobs -p | wc -l)"
  done
  rm -f $WORKSPACE/results/default-comparison/done-*
  rm -f $WORKSPACE/results/default-comparison/cmdlog-*
  echo "Finished with default comparison at `date`"
fi
#set -x

#----------------------------------
# Comparison summary
#----------------------------------
if [ "X$RUN_JR_COMP" = Xtrue ]; then
  if [ "X$RUN_DEFAULT_COMP" = Xtrue ]; then
    QALOG=$JR_COMP_DIR/logRootQA.log
    JRHTML=$WORKSPACE/upload/validateJR.html
    mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Generating comparison summary" || true
    echo 'Doing histogram, log and root comparison:'
    (${CMSBOT_PYTHON_CMD} $CMS_BOT_DIR/logRootQA.py $WORKSPACE/data/${COMPARISON_RELEASE} $WORKSPACE/data/PR-${PR_NUM} ${JR_COMP_DIR} $WORKSPACE/results/default-comparison  >> $QALOG 2>&1) || true
    (grep -a SUMMARY $QALOG | cut -d' ' -f2-100 >> $JR_COMP_DIR/qaResultsSummary.log 2>&1) || true
    echo "<html><body><h3>Default comparison: Workflows with failed comparisons</h3>" > $JRHTML
    echo "<table><tr><td>WF #</td><td>Failed</td></tr>" >> $JRHTML
    grep -a 'Histogram comparison details' $QALOG  | grep '\.log *\[[1-9][0-9]* *, *[1-9][0-9]*'  | sed 's|.*/default-comparison/\(\([^_]*\)_.*\)RelMonComp.*.log \[[1-9][0-9]* *, *\([1-9][0-9]*\) *,.*|<tr><td><a href="\1">\2</a></td><td align="right">\3</td></tr>|' >> $JRHTML
    if [ $(cat $JRHTML | wc -l) -eq 2 ] ; then
      echo "<tr><td>ALL OK</td><td>No errors</td></tr></table>" >> $JRHTML
    else
      echo "</table>" >> $JRHTML
    fi
    echo "<h3>Default comparison: Workflows with reco comparison differences</h3>" >> $JRHTML
    echo "<table><tr><td>WF #</td><td>Differences</td></tr>" >> $JRHTML
    grep -a 'JR results differ' $QALOG | awk '{ split($0,a," "); print "<tr><td><a href=\"validateJR/"a[5]"\">"a[5]"</a></td><td align=\"right\">"a[4]"</td></tr>" }' >> $JRHTML
    if [ $(tail -1 $JRHTML | grep "Differences" | wc -l) -eq 1 ] ; then
      echo "<tr><td>ALL OK</td><td>No differences</td></tr></table>" >> $JRHTML
    else
      echo "</table>" >> $JRHTML
    fi
    echo "<h3>Default comparison: Workflows with reco comparison failures</h3>" >> $JRHTML
    echo "<table><tr><td>WF #</td><td>Failures log</td></tr>" >> $JRHTML
    grep -a 'JR results failed' $QALOG | awk '{ split($0,a," "); print "<tr><td><a href=\"validateJR/"a[4]"\">"a[4]"</a></td><td align=\"right\"><a href=\"validateJR/"a[4]"/"a[4]".log\">log</a></td></tr>" }' >> $JRHTML
    if [ $(tail -1 $JRHTML | grep "Failures" | wc -l) -eq 1 ] ; then
      echo "<tr><td>ALL OK</td><td>No failures</td></tr></table>" >> $JRHTML
    else
      echo "</table>" >> $JRHTML
    fi
    echo "</body></html>" >> $JRHTML
    echo "FAILED_COMPARISON${TEST_FLAVOR_STR};OK,Comparison ${UC_TEST_FLAVOR} failed,See failed,/SDT/jenkins-artifacts/${COMP_UPLOAD_DIR}/validateJR.html" >> ${RESULTS_FILE}
  fi
fi

#-----------------------------------
# Comparisons of edm::TriggerResults
#-----------------------------------
RUN_TR_COMP=true # placeholder: to be configured upstream?
if [ "X$RUN_TR_COMP" = Xtrue ]; then
  echo "[`date`] Starting comparisons of edm::TriggerResults"
  mkdir -p ${WORKSPACE}/upload/triggerResults
  for WF in ${WORKFLOWS_TO_COMPARE//,/ }; do
    while [ $(jobs -p | wc -l) -ge ${NUM_PROC} ]; do sleep 5; done
    WF_DIR=`echo ${WF} | cut -d "/" -f1`
    (${CMS_BOT_DIR}/compareTriggerResults -r ${WORKSPACE}/data/${COMPARISON_RELEASE} -t ${WORKSPACE}/data/PR-${PR_NUM} \
      -f "*/${WF_DIR}/step*.root" -o ${WORKSPACE}/upload/triggerResults > ${WORKSPACE}/upload/triggerResults/${WF_DIR}.log 2>&1) || true &
    unset WF_DIR
  done
  unset WF
  echo "[`date`] Running comparisons of edm::TriggerResults ..."
fi
#-----------------------------------

#Nano Workflows summary
${NANO_TEST} && nano_summary

jobs
wait || true

if [ "X$RUN_TR_COMP" = Xtrue ]; then
  echo "[`date`] Finished comparisons of edm::TriggerResults"
  (${CMS_BOT_DIR}/compareTriggerResultsSummary -i ${WORKSPACE}/upload/triggerResults -f "*/*.json" \
    -o ${WORKSPACE}/upload/triggerResults/index.html -F html > ${WORKSPACE}/upload/triggerResults.log 2>&1) || true
  echo "[`date`] Summary of TriggerResults comparisons saved in ${WORKSPACE}/upload/triggerResults.log"
  echo "HLT_TRIGGER_COMPARISON${TEST_FLAVOR_STR};OK,HLT Trigger ${UC_TEST_FLAVOR} comparison,See results,/SDT/jenkins-artifacts/${COMP_UPLOAD_DIR}/triggerResults/" >> ${RESULTS_FILE}
  if [ -f ${JR_COMP_DIR}/qaResultsSummary.log ]; then
    (grep -a SUMMARY ${WORKSPACE}/upload/triggerResults.log | cut -d' ' -f2-100 >> ${JR_COMP_DIR}/qaResultsSummary.log 2>&1) || true
    sed -i "s|TriggerResults|[TriggerResults](${JENKINS_ARTIFACTS_URL}/${COMP_UPLOAD_DIR}/triggerResults)|g" ${JR_COMP_DIR}/qaResultsSummary.log
    echo "[`date`] One-line Summary of TriggerResults comparisons appended to ${JR_COMP_DIR}/qaResultsSummary.log"
  fi
fi

cd $WORKSPACE
mkdir -p upload/alternative-comparisons

#default-comparison
if [ "X${FILTER_FAILED_COMPARISON}" = "Xtrue" ] ; then
  mkdir -p $WORKSPACE/upload/extras
  for f in results/default-comparison/* ; do
    if [ -f $f ] ; then
      mv $f upload/
    elif [ ! -f $f/index.html ] ; then
      mv $f upload/
    elif [ -d $f ] ; then
      set +x
      while [ $(jobs -p | wc -l) -ge ${NUM_PROC} ] ; do sleep 1 ; done
      set -x
      wf=$(basename $f)
      $CMS_BOT_DIR/comparisons/filter-failed-comparison.py $f $WORKSPACE/upload >$WORKSPACE/upload/extras/$wf.log 2>&1 &
    fi
  done
  wait || true
else
  for f in results/default-comparison/* ; do
    [ -e $f ] && mv $f upload/
  done
fi

#alternative-comparison
alt_dir=results/alternative-comparison
for f in $(find ${alt_dir} -maxdepth 1 -name 'command*' -o -name '*.ps' -o -name '*.gz' -o -name '*.log' -o -name '*.txt') ; do
  mv $f upload/alternative-comparisons/
done

#JR-comparison
for x in $(find results/JR-comparison -maxdepth 3 -name 'command*' -o -name '*.log' -o -name '*.png' -type f) ; do
  f=$(echo $x | sed 's|results/JR-comparison/||')
  d=$(dirname upload/validateJR/$f)
  [ -d $d ] || mkdir -p $d
  mv results/JR-comparison/$f $d/
done

#nano
[ -d $WORKSPACE/results/nano ] && mv $WORKSPACE/results/nano upload/

#files
if [ -e results/files ] ; then
  mkdir -p upload/files
  for file in $(find results/files -mindepth 2 -maxdepth 2 -name '*' | sed 's|^results/files/||') ; do
    fname=$(basename $file)
    wfdir=$(dirname $file)
    mkdir -p upload/files/${wfdir}
    case $file in 
      */${COMPARISON_RELEASE}-*) SRC_FILE=../../../../../${BASELINE_DIR}/${wfdir}/$(echo $fname | sed "s|${COMPARISON_RELEASE}-||") ;;
      *)                     SRC_FILE=../../../../../${PR_BASELINE_DIR}/${wfdir}/$(echo $fname | sed "s|$PR_NUM-||") ;;
    esac
    ln -sf $SRC_FILE upload/files/$file
  done
fi

mkdir -p $WORKSPACE/testsResults
sed -i "s/^COMPARISON${TEST_FLAVOR_STR};RUNNING,/COMPARISON${TEST_FLAVOR_STR};$BUILD_NUMBER,/g" ${RESULTS_FILE}
mv ${RESULTS_FILE} $WORKSPACE/testsResults/

[ -e comparisonDetails.txt ] && mv comparisonDetails.txt upload/
${CMS_BOT_DIR}/report-pull-request-results "COMPARISON_READY" --report-url ${PR_RESULT_URL} \
  -f $WORKSPACE/wf_errors.txt --f2 $WORKSPACE/wf_non_consistent_das.txt \
  --missing_map $WORKSPACE/results/JR-comparison/missing_map.txt  --report-file $WORKSPACE/testsResults/20-comparison-report.res

if [ "${TEST_FLAVOR}" != "" ] ; then
  sed -i -e "s|## Comparison Summary|## ${UC_TEST_FLAVOR} Comparison Summary|" $WORKSPACE/testsResults/20-comparison-report.res
  mv $WORKSPACE/testsResults/20-comparison-report.res $WORKSPACE/testsResults/20-${TEST_FLAVOR}-comparison-report.res
  if [ -e $WORKSPACE/upload/nano/NANO_report.md ] ; then
    echo "**Nano size comparison Summary**:" >> $WORKSPACE/testsResults/21-${TEST_FLAVOR}-comparison-report.res
    echo "" >> $WORKSPACE/testsResults/21-${TEST_FLAVOR}-comparison-report.res
    cat $WORKSPACE/upload/nano/NANO_report.md >> $WORKSPACE/testsResults/21-${TEST_FLAVOR}-comparison-report.res
    echo "" >> $WORKSPACE/testsResults/21-${TEST_FLAVOR}-comparison-report.res
  fi
fi

if [ "$DRY_RUN" = "" ] ; then
  send_jenkins_artifacts $WORKSPACE/upload/ ${COMP_UPLOAD_DIR}/
  send_jenkins_artifacts $WORKSPACE/testsResults/ ${PR_BASELINE_JOBDIR}/testsResults/
fi
mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'success' -u "${BUILD_URL}" -d "Finished, please check results" || true
echo "All done at `date`"
