#!/usr/bin/env python3

import dataclasses
import datetime
import json
import logging
import os
import sys

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "shift"))
try:
    from github_utils import github_api
    import libib

    # noinspection PyUnresolvedReferences
    from libib import PackageInfo, ErrorInfo
except ImportError:
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "shift"))
    from github_utils import github_api
    import libib

    # noinspection PyUnresolvedReferences
    from libib import PackageInfo, ErrorInfo

cache_root = "/build/builds/cms-ib-notifier"


def get_commit_info(repo, commit):
    return github_api(
        uri="/repos/{}/commits/{}".format(repo, commit),
        method="GET",
    )


def isoparse(strDate):
    return datetime.datetime.strptime(strDate, "%Y-%m-%dT%H:%M:%SZ")

def main():
    mm_webhook_url = os.environ.get("MM_WEBHOOK_URL", "")

    libib.setup_logging(logging.DEBUG)
    libib.get_exitcodes()

    ib_dates = libib.get_ib_dates("default")

    commit_dates = {}

    changed_rels = set()
    for commit_id in sys.argv[1:]:
        print("Processing commit {}".format(commit_id))
        commit_info = get_commit_info("cms-sw/cms-sw.github.io", commit_id)
        if "sha" not in commit_info:
            print("Invalid or missing commit-id {}".format(commit_id))
            continue
        try:
            commit_author = commit_info["commit"]["author"]
        except KeyError:
            print("Commit {} has no author!".format(commit_id))
            continue
        if commit_author["email"] != "cmsbuild@cern.ch":
            print(
                "Commit {} not from cmsbuild: {} <{}>".format(
                    commit_id, commit_author["name"], commit_author["email"]
                )
            )
            continue

        commit_date = libib.date_fromisoformat(commit_author["date"])
        commit_dates[commit_id] = commit_date

        for change in commit_info["files"]:
            if not change["filename"].startswith("_data/CMSSW"):
                continue
            relname = change["filename"].replace("_data/", "").replace(".json", "")
            print("Release {} changed".format(relname))
            changed_rels.add(relname)

    if len(changed_rels) == 0:
        print("No releases changed")
        exit(0)

    newest_commit_date = max(commit_dates.values())
    newest_commit_id = [k for k, v in commit_dates.items() if v == newest_commit_date]
    newest_commit_id = newest_commit_id[0]

    report = []

    for ib_date in ib_dates:
        for rel in changed_rels:
            old_data_file = os.path.join(cache_root, "{}.json".format(rel))
            old_result = None
            if os.path.exists(old_data_file):
                print(f"Loading cached release {rel}")
                old_data = json.load(open(old_data_file, "r"))
                old_comparision = libib.get_ib_results(ib_date, None, old_data)
                if old_comparision:
                    _, old_result = libib.check_ib(old_comparision)
            else:
                print(f"No cache for release {rel}")

            new_data = libib.fetch(
                f"https://github.com/cms-sw/cms-sw.github.io/raw/{newest_commit_id}/data%2F{rel}.json"
            )
            new_comparision = libib.get_ib_results(ib_date, None, new_data)
            if new_comparision is None:
                continue

            _, new_result = libib.check_ib(new_comparision)

            for arch in new_result:
                for error in new_result[arch]["build"]:
                    if old_result and error in old_result[arch]["build"]:
                        continue

                    report.append(
                        f"| {rel} | {ib_date} | {arch} | [{error.name}]({error.url}) | {error.data[1]}x "
                        f"{error.data[0]} | "
                    )

                for error in new_result[arch]["utest"]:
                    if old_result and error in old_result[arch]["utest"]:
                        continue

                    report.append(
                        f"| {rel} | {ib_date} | {arch} | [{error.name}]({error.url}) | TBD | "
                    )

                for error in new_result[arch]["relval"]:
                    if old_result and error in old_result[arch]["relval"]:
                        continue

                    report.append(
                        f"| {rel} | {ib_date} | {arch} | [{error.name}]({error.url}) | {error.data} | "
                    )

    # changed_rels = "\n".join("* "+x for x in list(changed_rels))
    header = """@shifter New IB failures found, please check:

| Series | IB date | Architecture | Error | Additional data |
| --- | --- | --- | --- | --- |
"""
    if report:
        payload = {"text": header + "\n".join(report)}
        print("=== Report ===")
        print(payload["text"])

        jsondata = json.dumps(payload).encode("utf-8")
        workspace = os.getenv("WORKSPACE", os.path.expanduser("~"))
        with open("{}/payload.txt".format(workspace), "wb") as f:
            f.write(jsondata)
    else:
        print("No new failures")

    # Save new json files
    for rel in changed_rels:
        url_ = f"https://github.com/cms-sw/cms-sw.github.io/raw/{newest_commit_id}/_data%2F{rel}.json"
        data = libib.fetch(url_, libib.ContentType.TEXT)
        with open(os.path.join(cache_root, "{}.json".format(rel)), "w") as f:
            f.write(data)


if __name__ == "__main__":
    main()
