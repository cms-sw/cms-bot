#!/usr/bin/env python
import os, sys, json, socket, errno, re, urllib2, base64
from glob import glob
from datetime import datetime
from optparse import OptionParser
from os.path import basename, getctime, join
from os import getenv
from time import strftime, localtime, strptime, mktime
from hashlib import sha1
from commands import getstatusoutput

MAX_FILES_PUSH = 20
MAX_TIME_STOP = 120 #seconds
TIME_FORMAT = "%Y-%m-%d %H:%M:%S"

def esReportPackages(results):
  # Silently exit if we cannot contact elasticsearch
  es_hostname = getenv("ES_HOSTNAME")
  es_auth = getenv("ES_AUTH")
  if not es_hostname and not es_auth:
    return

  url = "https://%s/_bulk" % (es_hostname)

  request = urllib2.Request(url)
  if es_auth:
    base64string = base64.encodestring(es_auth).replace('\n', '')
    request.add_header("Authorization", "Basic %s" % base64string)
  request.get_method = lambda: 'POST'
  data = "\n".join(results) + "\n"
  try:
    result = urllib2.urlopen(request, data=data)
  except urllib2.HTTPError, e:
    print e
    try:
      print result.read()
    except:
      pass

def create_dir(dir_to_create):
  try:
    os.makedirs(dir_to_create)
  except OSError as exception:
    if exception.errno != errno.EEXIST:
      raise exception

def check_pid(pid):
    """ Check For the existence of a unix pid. """
    try:
        os.kill(pid, 0)
    except OSError:
        return False
    else:
        return True

if __name__ == "__main__":
  parent_dir = os.getenv("WORKSPACE", "")
  WORK_DIR = join(parent_dir, "pkg_mon")
  cmssw_base = os.getenv("CMSSW_BASE", "")
  SOURCE_DIR = join(cmssw_base, "src")
  
  parser = OptionParser(usage="%prog <-s|-e> -p <package>")
  parser.add_option("-s","--start", dest="start", action="store_true",
                    help="Building started for package", default=True)
  parser.add_option("-e","--stop", dest="start", action="store_false",
                    help="Building done for package", default=True)
  parser.add_option("-f","--force", dest="force", action="store_true",
                    help="Force pushing", default=False)
  parser.add_option("-p","--package", dest="pkg_name",
                    help="Package name to track", default=None)
  parser.add_option("--dry-run", dest="dryrun", action="store_true",
                    help="Do not push files to server", default=False)
  opts, args = parser.parse_args()

  if (not opts.pkg_name and opts.start):
    results = []
    cmssw_version = os.getenv("CMSSW_VERSION", "unknown")
    data = { "hostname": socket.gethostname(),
               "scram_arch": os.getenv("SCRAM_ARCH", "unknown"),
               "cmssw_version": cmssw_version,
            }
    header = { "index" : { "_index" : strftime("ib-scram-stats-%Y.%m.%d"),
                           "_type" : "cmssw_pkg_times",
              } }
    for p in glob(join(SOURCE_DIR, "*", "*")):
      pkg = re.match(SOURCE_DIR+"/(.+)", p).groups()[0]
      h = sha1(pkg + data["scram_arch"] + data["cmssw_version"]).hexdigest()
      header["index"]["_id"] = h
      data["package"] = pkg
      results.append(json.dumps(header))
      results.append(json.dumps(data))
    if opts.dryrun:
      print "Dry run specified, what I would have sent: \n" + str(results) 
    else:
      esReportPackages(results)
    exit(0)

  try:
    thread_id = os.fork()
  except OSError, e:
    print "Error while forking"
    sys.exit(1)
  if not thread_id == 0:
    sys.exit(0)

  pkg_name = opts.pkg_name
  create_dir(WORK_DIR)

  # We look for stale "push" dirs, move all the files back in the workdir and
  # remove them.
  pushDirs = glob("push_dir_*")
  pids = [p.replace("push_dir_", "") for p in pushDirs]
  stalePids = [p for p in pids if not check_pid(int(p))]
  staleDirs = ["push_dir_" + p for p in stalePids]
  for d in staleDirs:
    for f in glob(join(d, "*")):
      try:
        os.renames(f, join(WORK_DIR, basename(f)))
      except:
        pass

  # Create the file for the current invocation.
  prefix = opts.start and strftime("start_%s-") or strftime("stop_%s-")
  filename = prefix + pkg_name.replace("/",":")
  open(join(WORK_DIR, filename), "a").close()


  # When enough files are ready to push or enough time has passed, start
  # pushing to elasticsearch.
  fileLimitReached = len([f for f in os.listdir(WORK_DIR)]) > MAX_FILES_PUSH
  timestamps = sorted([int(basename(x).split("_")[1].split("-")[0])
                       for x in glob(join(WORK_DIR, "*"))])
  timeLimitReached = getctime(WORK_DIR) - int(timestamps.pop())

  if not fileLimitReached and not timeLimitReached and not opts.force and ( opts.start or opts.pkg_name): #Can force the push with force option or by calling end package without a package
    sys.exit(0)

  push_dir = "push_dir_"+str(os.getpid())
  try:
    os.rename(WORK_DIR, push_dir)
  except:
    sys.exit(0)

  results = []
  removables = []
  RE_FILE = "(start|stop)_([0-9]+)-(.*)"
  pushables = [f.replace(":", "/") for f in os.listdir(push_dir)]
  info = [re.match(RE_FILE, f).groups() for f in pushables]
  cmssw_version = os.getenv("CMSSW_VERSION", "unknown")
  defaults = { "hostname": socket.gethostname(),
               "scram_arch": os.getenv("SCRAM_ARCH", "unknown"),
               "cmssw_version": cmssw_version
             }
  m = re.match("(.*)_(20[0-9]{2}-[0-9]{2}-[0-9]{2}-[0-9]{4})", cmssw_version)
  if m:
    defaults["cmssw_queue"] = m.group(1)
    defaults["@timestamp"] = strftime("%Y-%m-%dT%H:%M:00.0", strptime(m.group(2), "%Y-%m-%d-%H%M"))
  starts = dict([(x[2],int(x[1])) for x in info if x[0] == "start"])
  stops = dict([(x[2],int(x[1])) for x in info if x[0] == "stop"])
  packages = set(x[2] for x in info)
  results = []
  for x in packages:
    h = sha1(x + defaults["scram_arch"] + defaults["cmssw_version"]).hexdigest()
    header = { "index" : { "_index" : strftime("ib-scram-stats-%Y.%m.%d"),
                           "_type" : "cmssw_pkg_times",
                           "_id" : h } }
    results.append(json.dumps(header))
    data = { "package": x}
    data.update(defaults)
    startTime = starts.get(x, None)
    stopTime = stops.get(x, None)
    if startTime:
      data["start"] = strftime(TIME_FORMAT,localtime(startTime))
    if stopTime:
      data["stop"] = strftime(TIME_FORMAT,localtime(stopTime))

    if startTime and stopTime:
      data["diff"] = stopTime - startTime
      removables.append(x.replace("/",":"))
    results.append(json.dumps(data))

  # Actually do the push to ES.
  if opts.dryrun:
    print "Dry run specified, what I would have sent: \n" + str(results)
    sys.exit(0)
  esReportPackages(results)

  for x in removables:
    cmd = "find %s -name \"*%s\" -delete" % (push_dir, x)
    err, out = getstatusoutput(cmd)
  for f in os.listdir(push_dir):
    while(True):
      try:
        os.renames(join(push_dir,f), join(WORK_DIR,f))
        break
      except:
        pass
